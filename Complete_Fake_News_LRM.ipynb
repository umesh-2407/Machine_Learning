{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg+RzuEFLeIYTPKbhm6sWQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umesh-2407/Machine_Learning/blob/main/Complete_Fake_News_LRM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6dgCChgxkoU",
        "outputId": "5a886b2a-8d51-4a03-8030-bc99b981f7be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        darrel lucu hous dem aid even see comey letter...\n",
            "1        daniel j flynn flynn hillari clinton big woman...\n",
            "2                   consortiumnew com truth might get fire\n",
            "3        jessica purkiss civilian kill singl us airstri...\n",
            "4        howard portnoy iranian woman jail fiction unpu...\n",
            "                               ...                        \n",
            "20795    jerom hudson rapper trump poster child white s...\n",
            "20796    benjamin hoffman n f l playoff schedul matchup...\n",
            "20797    michael j de la merc rachel abram maci said re...\n",
            "20798    alex ansari nato russia hold parallel exercis ...\n",
            "20799                            david swanson keep f aliv\n",
            "Name: content, Length: 20800, dtype: object\n",
            "['darrel lucu hous dem aid even see comey letter jason chaffetz tweet'\n",
            " 'daniel j flynn flynn hillari clinton big woman campu breitbart'\n",
            " 'consortiumnew com truth might get fire' ...\n",
            " 'michael j de la merc rachel abram maci said receiv takeov approach hudson bay new york time'\n",
            " 'alex ansari nato russia hold parallel exercis balkan'\n",
            " 'david swanson keep f aliv']\n",
            "[1 0 1 ... 0 1 1]\n",
            "  (0, 267)\t0.2701012497770876\n",
            "  (0, 2483)\t0.36765196867972083\n",
            "  (0, 2959)\t0.24684501285337127\n",
            "  (0, 3600)\t0.3598939188262558\n",
            "  (0, 3792)\t0.27053324808454915\n",
            "  (0, 4973)\t0.23331696690935097\n",
            "  (0, 7005)\t0.2187416908935914\n",
            "  (0, 7692)\t0.24785219520671598\n",
            "  (0, 8630)\t0.2921251408704368\n",
            "  (0, 8909)\t0.36359638063260746\n",
            "  (0, 13473)\t0.2565896679337956\n",
            "  (0, 15686)\t0.2848506356272864\n",
            "  (1, 1497)\t0.2939891562094648\n",
            "  (1, 1894)\t0.15521974226349364\n",
            "  (1, 2223)\t0.3827320386859759\n",
            "  (1, 2813)\t0.19094574062359204\n",
            "  (1, 3568)\t0.26373768806048464\n",
            "  (1, 5503)\t0.7143299355715573\n",
            "  (1, 6816)\t0.1904660198296849\n",
            "  (1, 16799)\t0.30071745655510157\n",
            "  (2, 2943)\t0.3179886800654691\n",
            "  (2, 3103)\t0.46097489583229645\n",
            "  (2, 5389)\t0.3866530551182615\n",
            "  (2, 5968)\t0.3474613386728292\n",
            "  (2, 9620)\t0.49351492943649944\n",
            "  :\t:\n",
            "  (20797, 3643)\t0.2115550061362374\n",
            "  (20797, 7042)\t0.21799048897828685\n",
            "  (20797, 8364)\t0.22322585870464115\n",
            "  (20797, 8988)\t0.36160868928090795\n",
            "  (20797, 9518)\t0.29542040034203126\n",
            "  (20797, 9588)\t0.17455348025522197\n",
            "  (20797, 10306)\t0.08038079000566466\n",
            "  (20797, 12138)\t0.24778257724396505\n",
            "  (20797, 12344)\t0.27263457663336677\n",
            "  (20797, 13122)\t0.24825263521976057\n",
            "  (20797, 14967)\t0.3115945315488075\n",
            "  (20797, 15295)\t0.08159261204402356\n",
            "  (20797, 16996)\t0.08315655906109998\n",
            "  (20798, 350)\t0.2844693781907258\n",
            "  (20798, 588)\t0.3112141524638974\n",
            "  (20798, 1125)\t0.4460515589182237\n",
            "  (20798, 5032)\t0.40837014502395297\n",
            "  (20798, 6889)\t0.3249628569429943\n",
            "  (20798, 10177)\t0.31924963701870285\n",
            "  (20798, 11052)\t0.4460515589182237\n",
            "  (20798, 13046)\t0.2236326748827061\n",
            "  (20799, 377)\t0.5677577267055112\n",
            "  (20799, 3623)\t0.37927626273066584\n",
            "  (20799, 8036)\t0.45983893273780013\n",
            "  (20799, 14852)\t0.5677577267055112\n",
            "[0 0 0 ... 0 0 1]\n",
            "Accuracy Score of Trainig data :  0.9863581730769231\n",
            "[1 0 1 ... 1 1 0]\n",
            "Accuracy Score of Test data :  0.9790865384615385\n",
            "The News is Fake\n",
            "[1]\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#Printing Stop Words\n",
        "#print(stopwords.words('english'))\n",
        "\n",
        "#Loading Dataset to pandas Datafarame\n",
        "news_dataset = pd.read_csv('/content/drive/MyDrive/ML_DataSets/Fake_News_Detection_1/train.csv')\n",
        "\n",
        "news_dataset.shape\n",
        "\n",
        "#Print 5 first rows of the dataframe\n",
        "news_dataset.head()\n",
        "\n",
        "#counting number of Missing values in dataset\n",
        "news_dataset.isnull().sum()\n",
        "\n",
        "# Replacing null values with empty string\n",
        "news_dataset = news_dataset.fillna('')\n",
        "\n",
        "# merging the autor name and news title\n",
        "news_dataset['content'] = news_dataset['author'] + ' ' + news_dataset['title']\n",
        "\n",
        "#Pirinting Datset\n",
        "#print(news_dataset['content'])\n",
        "\n",
        "# Separating Data and Label\n",
        "X = news_dataset.drop(columns='label', axis=1)\n",
        "Y = news_dataset['label']\n",
        "\n",
        "port_stem = PorterStemmer()\n",
        "\n",
        "def stemming(content):\n",
        "  stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
        "  stemmed_content = stemmed_content.lower()\n",
        "  stemmed_content = stemmed_content.split()\n",
        "  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "  stemmed_content = ' '.join(stemmed_content)\n",
        "  return stemmed_content\n",
        "\n",
        "news_dataset['content'] = news_dataset['content'].apply(stemming)\n",
        "\n",
        "print(news_dataset['content'])\n",
        "\n",
        "#Separating the data and label\n",
        "\n",
        "X = news_dataset['content'].values\n",
        "Y = news_dataset['label'].values\n",
        "\n",
        "print(X)\n",
        "print(Y)\n",
        "Y.shape\n",
        "\n",
        "#Converting the Textual Data into NUmerical Data\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(X)\n",
        "\n",
        "X = vectorizer.transform(X)\n",
        "\n",
        "print(X)\n",
        "\n",
        "#SPLITTING DATASET INTO TRAIN AND TEST\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
        "\n",
        "#TRAINIG THE LOGISTIC REGRESSION MODEL\n",
        "model = LogisticRegression()\n",
        "\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "#EVALUATION\n",
        "\n",
        "#ACCURACY SCORE on Training Data\n",
        "\n",
        "X_train_Prediction = model.predict(X_train)\n",
        "Training_Data_Accuracy = accuracy_score(X_train_Prediction, Y_train)\n",
        "\n",
        "print(X_train_Prediction)\n",
        "print('Accuracy Score of Trainig data : ',Training_Data_Accuracy)\n",
        "\n",
        "#ACCURACY SCORE on Test Data\n",
        "\n",
        "X_test_Prediction = model.predict(X_test)\n",
        "Test_Data_Accuracy = accuracy_score(X_test_Prediction, Y_test)\n",
        "\n",
        "print(X_test_Prediction)\n",
        "print('Accuracy Score of Test data : ',Test_Data_Accuracy)\n",
        "\n",
        "\n",
        "#MAKING A PREDICTIVE SYSTEM\n",
        "\n",
        "X_new = X_test[99]\n",
        "\n",
        "prediction = model.predict(X_new)\n",
        "\n",
        "if (prediction[0]==0):\n",
        "  print('The News is Real')\n",
        "else:\n",
        "  print('The News is Fake')\n",
        "\n",
        "print(prediction)\n",
        "print(Y_test[99])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PLERJ7n9yIMp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}